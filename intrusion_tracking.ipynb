{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Person Tracking with Virtual Fence Detection\n",
    "1. Drawing up to 3 virtual boundary lines on an input video\n",
    "2. Detecting and tracking persons with YOLOv8 + SFSORT\n",
    "3. Counting and visualizing crossings of the boundary lines\n",
    "4. Saving an annotated output video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from random import randrange\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from src.SFSORT import SFSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using video: ./data\\test.avi\n",
      "Using model: ./weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Input videos\n",
    "ROOT = r\"./\"  \n",
    "DATA_DIR    = os.path.join(ROOT, \"data\")\n",
    "VIDEO_FILES = glob.glob(os.path.join(DATA_DIR, \"*.avi\"))\n",
    "\n",
    "# YOLO weights\n",
    "WEIGHTS_DIR = os.path.join(ROOT, \"weights\")\n",
    "MODEL_PATH  = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_DIR  = os.path.join(ROOT, \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_VIDEO = os.path.join(OUTPUT_DIR, \"tracked_output_MOT.mp4\")\n",
    "OUTPUT_VIDEO_PATH = os.path.join(OUTPUT_DIR, \"tracked_output_MOT.mp4\")\n",
    "\n",
    "assert len(VIDEO_FILES)==1, f\"expected 1 video in {DATA_DIR}, found {VIDEO_FILES}\"\n",
    "print(\"Using video:\", VIDEO_FILES[0])\n",
    "print(\"Using model:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Helper Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class boundaryLine:\n",
    "    \"\"\"\n",
    "    Virtual fence line with counts for two directions.\n",
    "\n",
    "    Attributes:\n",
    "        id (int): Unique identifier.\n",
    "        p0, p1 (tuple[int,int]): Endpoints of the line.\n",
    "        count_forward (int): Count of crossings in forward direction.\n",
    "        count_backward (int): Count of crossings in backward direction.\n",
    "    \"\"\"\n",
    "    def __init__(self, line_id, line=[(0, 0), (0, 0)]):\n",
    "        self.id = line_id\n",
    "        self.p0 = line[0]\n",
    "        self.p1 = line[1]\n",
    "        # Drawing style\n",
    "        self.color = (0, 255, 255)\n",
    "        self.lineThinkness = 4\n",
    "        self.textColor = (0, 255, 255)\n",
    "        self.textSize = 4\n",
    "        self.textThinkness = 2\n",
    "        # Crossing counts\n",
    "        self.count1 = 0\n",
    "        self.count2 = 0\n",
    "\n",
    "def line_vectorize(point1, point2):\n",
    "    \"\"\"Return 2D vector from p1 to p2.\"\"\"\n",
    "    a = point2[0] - point1[0]\n",
    "    b = point2[1] - point1[1]\n",
    "    return [a, b]\n",
    "\n",
    "def calcVectorAngle(point1, point2, point3, point4):\n",
    "    u = np.array(line_vectorize(point1, point2))\n",
    "    v = np.array(line_vectorize(point3, point4))\n",
    "    i = np.inner(u, v)\n",
    "    n = LA.norm(u) * LA.norm(v)\n",
    "    c = i / n\n",
    "    a = np.rad2deg(np.arccos(np.clip(c, -1.0, 1.0)))\n",
    "    return a if u[0]*v[1]-u[1]*v[0] < 0 else 360 - a\n",
    "\n",
    "def checkIntersect(p1, p2, p3, p4):\n",
    "    tc1 = (p1[0] - p2[0]) * (p3[1] - p1[1]) + (p1[1] - p2[1]) * (p1[0] - p3[0])\n",
    "    tc2 = (p1[0] - p2[0]) * (p4[1] - p1[1]) + (p1[1] - p2[1]) * (p1[0] - p4[0])\n",
    "    td1 = (p3[0] - p4[0]) * (p1[1] - p3[1]) + (p3[1] - p4[1]) * (p3[0] - p1[0])\n",
    "    td2 = (p3[0] - p4[0]) * (p2[1] - p3[1]) + (p3[1] - p4[1]) * (p3[0] - p2[0])\n",
    "    return tc1 * tc2 < 0 and td1 * td2 < 0\n",
    "\n",
    "def checkLineCross(boundary_line, trajectory, track_id):\n",
    "    \"\"\"\n",
    "    Update line counts if track segment crosses the boundary.\n",
    "    Returns a message if crossing occurred, else None.\n",
    "    \"\"\"\n",
    "    traj_p0 = (trajectory[0], trajectory[1])\n",
    "    traj_p1 = (trajectory[2], trajectory[3])\n",
    "    bLine_p0 = (boundary_line.p0[0], boundary_line.p0[1])\n",
    "    bLine_p1 = (boundary_line.p1[0], boundary_line.p1[1])\n",
    "    intersect = checkIntersect(traj_p0, traj_p1, bLine_p0, bLine_p1)\n",
    "    if intersect:\n",
    "        angle = calcVectorAngle(traj_p0, traj_p1, bLine_p0, bLine_p1)\n",
    "        if 15 < angle < 165:\n",
    "            boundary_line.count1 += 1\n",
    "        elif 195 < angle < 345:\n",
    "            boundary_line.count2 += 1\n",
    "        return f'ID {track_id} crossed line {boundary_line.id}!'\n",
    "    return None\n",
    "\n",
    "def drawBoundaryLine(img, line):\n",
    "    \"\"\"Draw all boundary lines and their counts on the frame.\"\"\"\n",
    "    x1, y1 = line.p0\n",
    "    x2, y2 = line.p1\n",
    "    cv2.line(img, (x1, y1), (x2, y2), line.color, line.lineThinkness)\n",
    "    cv2.putText(img, str(line.count1), (x1, y1), cv2.FONT_HERSHEY_PLAIN, line.textSize, line.textColor, line.textThinkness)\n",
    "    cv2.putText(img, str(line.count2), (x2, y2), cv2.FONT_HERSHEY_PLAIN, line.textSize, line.textColor, line.textThinkness)\n",
    "    cv2.drawMarker(img, (x1, y1), line.color, cv2.MARKER_TRIANGLE_UP, 16, 4)\n",
    "    cv2.drawMarker(img, (x2, y2), line.color, cv2.MARKER_TILTED_CROSS, 16, 4)\n",
    "\n",
    "def drawBoundaryLines(img, boundaryLines):\n",
    "    for line in boundaryLines:\n",
    "        drawBoundaryLine(img, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load Video and Draw Boundaries - Interactive: draw up to 3 lines on the first frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw up to 3 boundary lines. Press 'q' to confirm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(VIDEO_FILES) != 1:\n",
    "    print(VIDEO_FILES)\n",
    "    raise ValueError(\"There should be exactly one .mp4 file in the folder.\")\n",
    "video_path = VIDEO_FILES[0]\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    raise RuntimeError(\"Failed to read first frame.\")\n",
    "\n",
    "# Interactive drawing\n",
    "boundary_points = []\n",
    "drawing = False\n",
    "current_line = []\n",
    "\n",
    "def draw_line(event, x, y, flags, param):\n",
    "    global drawing, current_line, boundary_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        current_line = [(x, y)]\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        temp_img = frame.copy()\n",
    "        cv2.line(temp_img, current_line[0], (x, y), (0, 255, 255), 2)\n",
    "        cv2.imshow(\"Draw Lines (up to 3)\", temp_img)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        current_line.append((x, y))\n",
    "        boundary_points.append(tuple(current_line))\n",
    "        cv2.line(frame, current_line[0], current_line[1], (0, 255, 255), 2)\n",
    "        cv2.imshow(\"Draw Lines (up to 3)\", frame)\n",
    "\n",
    "cv2.namedWindow(\"Draw Lines (up to 3)\")\n",
    "cv2.setMouseCallback(\"Draw Lines (up to 3)\", draw_line)\n",
    "\n",
    "print(\"Draw up to 3 boundary lines. Press 'q' to confirm.\")\n",
    "while True:\n",
    "    cv2.imshow(\"Draw Lines (up to 3)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or len(boundary_points) >= 3:\n",
    "        break\n",
    "cv2.destroyWindow(\"Draw Lines (up to 3)\")\n",
    "\n",
    "# Create BoundaryLine objects\n",
    "bLines = [boundaryLine(i+1, list(pts)) for i, pts in enumerate(boundary_points)]\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # rewind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Main Tracking Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 206/1050 [00:47<02:59,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "ID 37 crossed line 1!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 251/1050 [00:57<02:53,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "ID 39 crossed line 1!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 284/1050 [01:04<02:51,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "ID 15 crossed line 2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 288/1050 [01:05<02:52,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "ID 19 crossed line 2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 334/1050 [01:15<02:39,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "ID 38 crossed line 2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 405/1050 [01:32<02:24,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n",
      "ID 43 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 463/1050 [01:44<02:08,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "ID 50 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 703/1050 [02:39<01:16,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n",
      "ID 48 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 719/1050 [02:43<01:19,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719\n",
      "ID 60 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 797/1050 [03:01<00:56,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797\n",
      "ID 40 crossed line 1!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 934/1050 [03:32<00:25,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934\n",
      "ID 68 crossed line 2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 937/1050 [03:33<00:26,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937\n",
      "ID 76 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 940/1050 [03:33<00:25,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940\n",
      "ID 69 crossed line 2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 961/1050 [03:38<00:21,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961\n",
      "ID 56 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 971/1050 [03:41<00:18,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n",
      "ID 72 crossed line 3!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [03:59<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracked video saved at: ./outputs\\tracked_output_MOT.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(MODEL_PATH, 'detect')\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Tracker parameters (adjust as needed)\n",
    "tracker_arguments = {\n",
    "    \"dynamic_tuning\": True,\n",
    "    \"high_th\": 0.5,\n",
    "    \"low_th\": 0.2,\n",
    "    \"match_th_first\": 0.4,\n",
    "    \"match_th_first_m\": 0.05,\n",
    "    \"match_th_second\": 0.4,\n",
    "    \"marginal_timeout\": int(1.1*frame_rate), \n",
    "    \"central_timeout\": int(1.4*frame_rate),  \n",
    "    \"horizontal_margin\": int(0.1*frame_width),  \n",
    "    \"vertical_margin\": int(0.1*frame_height), \n",
    "    \"frame_width\": frame_width,  # To be set dynamically\n",
    "    \"frame_height\": frame_height  # To be set dynamically\n",
    "}\n",
    "\n",
    "\n",
    "tracker = SFSORT(tracker_arguments)\n",
    "\n",
    "# Setup video writer for output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, frame_rate, (frame_width, frame_height))\n",
    "colors = {}\n",
    "intruders = {}\n",
    "tracks = {}\n",
    "\n",
    "\n",
    "for frame_no in tqdm(range(frame_count)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"End of video reached or error reading frame {frame_no}.\")\n",
    "        break\n",
    "    prediction = model.predict(frame, imgsz=(800,1440),\n",
    "                               conf=0.1, iou=0.45, half=False,\n",
    "                               max_det=60, classes=0, verbose=False)\n",
    "    \n",
    "    # exclude extra info from the predictions\n",
    "    predictionResults = prediction[0].boxes.cpu().numpy()\n",
    "\n",
    "    box_list = predictionResults.xyxy\n",
    "    score_list = predictionResults.conf\n",
    "\n",
    "    if box_list.shape[0] == 0:\n",
    "      print(f'no detection found in {frame_no+1}')\n",
    "      drawBoundaryLines(frame,bLines)\n",
    "      # cv2.imwrite(os.path.join(folder_path,str(frame_no+1) +'.jpg'),frame)\n",
    "      out.write(frame)\n",
    "      continue\n",
    "\n",
    "    # Update tracker with detections\n",
    "    track_list = tracker.update(box_list, score_list)\n",
    "\n",
    "\n",
    "    # Annotate frame with tracking results\n",
    "    for track in track_list:\n",
    "        bbox, track_id = track[0], int(track[1])\n",
    "        if track_id not in tracks:\n",
    "          tracks[track_id] = bbox\n",
    "        prev_box = tracks[track_id]\n",
    "        \n",
    "        \n",
    "        x0, y0, x1, y1 = map(int, bbox)\n",
    "        cx,cy = (x0+x1)/2 , (y0+y1)/2\n",
    "\n",
    "        \n",
    "        prev_x0,prev_y0,prev_x1,prev_y1 = map(int, prev_box)\n",
    "        prev_cx,prev_cy = (prev_x0+prev_x1)/2 , (prev_y0+prev_y1)/2\n",
    "        \n",
    "        crossed = [None]*len(bLines)\n",
    "        for j,line in enumerate(bLines):\n",
    "          crossed[j] = checkLineCross(line, [prev_cx,prev_cy, cx,cy], track_id)\n",
    "\n",
    "        if track_id not in colors:\n",
    "          colors[track_id] =  (randrange(255), randrange(255), randrange(255))\n",
    "\n",
    "        color = colors[track_id]\n",
    "        track_thickness = 1\n",
    "        if any(crossed):\n",
    "          if track_id not in intruders:\n",
    "            intruders[track_id] = [[cx,cy]]\n",
    "          message = [m for m in crossed if m is not None]\n",
    "          cv2.putText(frame, str(message[0]), (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "          print(frame_no+1)\n",
    "          print(str(message[0]))\n",
    "\n",
    "        # drawBoundaryLines(frame,bLines)\n",
    "        \n",
    "        if track_id in intruders:\n",
    "          color = (0,0,255)\n",
    "          track_thickness = 2\n",
    "          intruders[track_id].append([cx,cy])\n",
    "          cv2.polylines(frame, np.array([intruders[track_id]], np.int32), False, (255,255,255), 4)\n",
    "\n",
    "        frame = cv2.rectangle(frame, (x0, y0), (x1, y1), color, track_thickness)\n",
    "        cv2.putText(frame, str(track_id), (x0, y0-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, track_thickness)\n",
    "        tracks[track_id] = bbox\n",
    "\n",
    "    drawBoundaryLines(frame,bLines)\n",
    "    # cv2.imwrite(os.path.join(folder_path,str(frame_no+1) +'.jpg'),frame)\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources for this video\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Tracked video saved at: {OUTPUT_VIDEO_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
